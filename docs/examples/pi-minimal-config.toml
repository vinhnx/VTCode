# Example vtcode.toml configuration for pi-inspired minimal mode
#
# This configuration reduces system prompt overhead from ~7,800 tokens to ~700 tokens
# Based on: https://mariozechner.at/posts/2025-11-30-pi-coding-agent/

[agent]
# Use minimal system prompt mode (pi-inspired)
# Options: "minimal" | "lightweight" | "default" | "specialized"
# - minimal: ~500-800 tokens (87% reduction, best for power users)
# - lightweight: ~1-2k tokens (resource-constrained operations)
# - default: ~6-7k tokens (current behavior, comprehensive)
# - specialized: ~7-8k tokens (complex refactoring)
system_prompt_mode = "minimal"

# Provider configuration
provider = "anthropic"
default_model = "claude-sonnet-4-5"

# Temperature - lower for more deterministic responses
temperature = 0.7

# Context optimization
[tools]
# Reduce repeated tool call warnings
max_repeated_tool_calls = 3

[mcp]
# Optional: Disable MCP to reduce context overhead (13-18k tokens per server)
# enabled = false

# Recommended: Use CLI tools instead of MCP
# See ~/.vtcode/tools/ for pi-style progressive disclosure
