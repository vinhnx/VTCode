{
  "google": {
    "id": "google",
    "env": [
      "GOOGLE_API_KEY",
      "GEMINI_API_KEY"
    ],
    "api": "https://generativelanguage.googleapis.com/v1beta",
    "name": "Google Gemini",
    "doc": "https://ai.google.dev/gemini-api/docs/models",
    "default_model": "gemini-3-flash-preview",
    "models": {
      "gemini-3.1-pro-preview": {
        "id": "gemini-3.1-pro-preview",
        "name": "Gemini 3.1 Pro Preview",
        "description": "Latest Gemini 3.1 Pro flagship model with improved thinking, efficiency, and factual consistency",
        "version": "preview",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "video",
            "audio",
            "pdf"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1048576,
        "output_tokens": 65536,
        "capabilities": {
          "caching": true,
          "code_execution": true,
          "batch_api": true,
          "structured_output": true,
          "search_grounding": true,
          "url_context": true,
          "thinking": true
        }
      },
      "gemini-3.1-pro-preview-customtools": {
        "id": "gemini-3.1-pro-preview-customtools",
        "name": "Gemini 3.1 Pro Preview (Custom Tools)",
        "description": "Gemini 3.1 Pro variant optimized for agentic workflows using custom tools and bash",
        "version": "preview",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "video",
            "audio",
            "pdf"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1048576,
        "output_tokens": 65536,
        "capabilities": {
          "caching": true,
          "code_execution": true,
          "batch_api": true,
          "structured_output": true,
          "search_grounding": true,
          "url_context": true,
          "thinking": true
        }
      },
      "gemini-3-pro-preview": {
        "id": "gemini-3-pro-preview",
        "name": "Gemini 3 Pro Preview",
        "description": "Preview of next-generation Gemini 3 Pro model with advanced reasoning and capabilities",
        "version": "preview",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "video",
            "audio",
            "pdf"
          ],
          "output": [
            "text"
          ]
        },
        "context": 2097152,
        "output_tokens": 65536,
        "capabilities": {
          "caching": true,
          "code_execution": true,
          "batch_api": true,
          "structured_output": true,
          "search_grounding": true,
          "url_context": true,
          "thinking": true
        }
      },
      "gemini-3-flash-preview": {
        "id": "gemini-3-flash-preview",
        "name": "Gemini 3 Flash",
        "description": "Our most intelligent model built for speed, combining frontier intelligence with superior search and grounding",
        "version": "preview",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "video",
            "audio",
            "pdf"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1048576,
        "output_tokens": 65536,
        "capabilities": {
          "caching": true,
          "code_execution": true,
          "batch_api": true,
          "structured_output": true,
          "search_grounding": true,
          "url_context": true,
          "thinking": true
        }
      }
    }
  },
  "openai": {
    "id": "openai",
    "env": [
      "OPENAI_API_KEY"
    ],
    "api": "https://api.openai.com/v1",
    "name": "OpenAI",
    "doc": "https://platform.openai.com/docs/models",
    "models": {
      "gpt-5.2": {
        "id": "gpt-5.2",
        "name": "GPT-5.2",
        "description": "Preferred GPT-5.2 identifier with improved reasoning and coding capabilities.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 400000
      },
      "gpt-5.1": {
        "id": "gpt-5.1",
        "name": "GPT-5.1",
        "description": "Latest flagship reasoning model with Responses API, reasoning + verbosity controls, and coding tools.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 400000
      },
      "gpt-5.1-mini": {
        "id": "gpt-5.1-mini",
        "name": "GPT-5.1 Mini",
        "description": "Lightweight GPT-5.1 variant optimized for fast responses and cost-efficiency.",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000
      },
      "gpt-5": {
        "id": "gpt-5",
        "name": "GPT-5",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 400000
      },
      "gpt-5-codex": {
        "id": "gpt-5-codex",
        "name": "GPT-5 Codex",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 400000
      },
      "gpt-5-mini": {
        "id": "gpt-5-mini",
        "name": "GPT-5 Mini",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000
      },
      "gpt-5-nano": {
        "id": "gpt-5-nano",
        "name": "GPT-5 Nano",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000
      },
      "codex-mini-latest": {
        "id": "codex-mini-latest",
        "name": "Codex Mini (Latest)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000
      },
      "gpt-oss-20b": {
        "id": "gpt-oss-20b",
        "name": "GPT-OSS 20B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "gpt-oss-120b": {
        "id": "gpt-oss-120b",
        "name": "GPT-OSS 120B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      }
    }
  },
  "huggingface": {
    "id": "huggingface",
    "env": [
      "HF_TOKEN"
    ],
    "api": "https://router.huggingface.co/v1",
    "name": "Hugging Face Inference Providers",
    "description": "OpenAI-compatible router for hosted models via Hugging Face Inference Providers.",
    "doc": "https://huggingface.co/docs/inference-providers",
    "default_model": "openai/gpt-oss-120b",
    "models": {
      "google/gemma-2-2b-it": {
        "id": "google/gemma-2-2b-it",
        "name": "Gemma 2 2B IT",
        "description": "A text-generation model trained to follow instructions.",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 8192,
        "capabilities": {
          "structured_output": true
        }
      },
      "Qwen/Qwen3-Coder-480B-A35B-Instruct": {
        "id": "Qwen/Qwen3-Coder-480B-A35B-Instruct",
        "name": "Qwen3 Coder 480B A35B Instruct",
        "description": "Powerful text generation model for coding.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "openai/gpt-oss-120b": {
        "id": "openai/gpt-oss-120b",
        "name": "GPT-OSS 120B",
        "description": "Great text generation model with top-notch tool calling capabilities.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "zai-org/GLM-5": {
        "id": "zai-org/GLM-5",
        "name": "GLM-5",
        "description": "Z.AI GLM-5 flagship foundation model available via Hugging Face router.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "capabilities": {
          "structured_output": true
        }
      },
      "Qwen/Qwen3-4B-Thinking-2507": {
        "id": "Qwen/Qwen3-4B-Thinking-2507",
        "name": "Qwen3 4B Thinking 2507",
        "description": "A powerful small model with reasoning capabilities.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 32768,
        "capabilities": {
          "structured_output": true
        }
      },
      "Qwen/Qwen2.5-7B-Instruct-1M": {
        "id": "Qwen/Qwen2.5-7B-Instruct-1M",
        "name": "Qwen2.5 7B Instruct 1M",
        "description": "Strong conversational model that supports very long instructions.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1048576,
        "capabilities": {
          "structured_output": true
        }
      },
      "Qwen/Qwen2.5-Coder-32B-Instruct": {
        "id": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "name": "Qwen2.5 Coder 32B Instruct",
        "description": "Text generation model used to write code.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "deepseek-ai/DeepSeek-R1": {
        "id": "deepseek-ai/DeepSeek-R1",
        "name": "DeepSeek R1",
        "description": "Powerful reasoning based open large language model.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "deepseek-ai/DeepSeek-V3.2": {
        "id": "deepseek-ai/DeepSeek-V3.2",
        "name": "DeepSeek V3.2",
        "description": "DeepSeek V3.2 served via Hugging Face Inference Providers (OpenAI-compatible chat endpoint).",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "openai/gpt-oss-20b": {
        "id": "openai/gpt-oss-20b",
        "name": "GPT-OSS 20B",
        "description": "OpenAI GPT-OSS 20B routed through Hugging Face's OpenAI-compatible endpoint.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "capabilities": {
          "structured_output": true
        }
      },
      "zai-org/GLM-5-Flash:novita": {
        "id": "zai-org/GLM-5-Flash:novita",
        "name": "GLM-5-Flash (Novita)",
        "description": "Z.AI GLM-5-Flash lightweight model via Novita inference provider on HuggingFace router. High-speed, completely free, and optimized for agentic coding.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "capabilities": {
          "structured_output": true
        }
      },
      "zai-org/GLM-5:novita": {
        "id": "zai-org/GLM-5:novita",
        "name": "GLM-5 (Novita)",
        "description": "Z.ai's flagship open-source foundation model engineered for complex systems design and long-horizon agent workflows. Built for expert developers, it delivers production-grade performance on large-scale programming tasks, rivaling leading closed-source models. With advanced agentic planning, deep backend reasoning, and iterative self-correction, GLM-5 moves beyond code generation to full-system construction and autonomous execution.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 202752,
        "capabilities": {
          "structured_output": true,
          "reasoning_effort": true
        }
      }
    }
  },
  "anthropic": {
    "id": "anthropic",
    "env": [
      "ANTHROPIC_API_KEY"
    ],
    "api": "https://api.anthropic.com/v1",
    "name": "Anthropic",
    "doc": "https://docs.anthropic.com/claude/docs/models-overview",
    "default_model": "claude-sonnet-4-5-20250929",
    "models": {
      "claude-sonnet-4-5-20250929": {
        "id": "claude-sonnet-4-5-20250929",
        "name": "Claude Sonnet 4.5",
        "description": "Latest flagship model for complex agents and coding. Optimal balance of intelligence, speed, and cost.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 64000,
        "status": "current"
      },
      "claude-haiku-4-5-20251001": {
        "id": "claude-haiku-4-5-20251001",
        "name": "Claude Haiku 4.5",
        "description": "Fastest model with near-frontier intelligence. Most cost-effective option.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 64000,
        "status": "current"
      },
      "claude-opus-4-1-20250805": {
        "id": "claude-opus-4-1-20250805",
        "name": "Claude Opus 4.1",
        "description": "Exceptional model for specialized reasoning tasks. Highest reasoning capability.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 32000,
        "status": "current"
      },
      "claude-opus-4-6": {
        "id": "claude-opus-4-6",
        "name": "Claude Opus 4.6",
        "description": "Next-gen flagship model with extended and adaptive thinking. 200K context with 1M beta.",
        "reasoning": true,
        "effort": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 128000,
        "status": "current"
      },
      "claude-sonnet-4-6": {
        "id": "claude-sonnet-4-6",
        "name": "Claude Sonnet 4.6",
        "description": "Balanced flagship model for coding with extended and adaptive thinking. 200K context with 1M beta.",
        "reasoning": true,
        "effort": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 128000,
        "status": "current"
      },
      "claude-sonnet-4-5": {
        "id": "claude-sonnet-4-5",
        "name": "Claude Sonnet 4.5 (alias)",
        "description": "Alias for latest Claude Sonnet 4.5. Auto-updates with new releases.",
        "alias": "claude-sonnet-4-5-20250929",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "status": "stable"
      },
      "claude-haiku-4-5": {
        "id": "claude-haiku-4-5",
        "name": "Claude Haiku 4.5 (alias)",
        "description": "Alias for latest Claude Haiku 4.5. Auto-updates with new releases.",
        "alias": "claude-haiku-4-5-20251001",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "status": "stable"
      },
      "claude-opus-4-1": {
        "id": "claude-opus-4-1",
        "name": "Claude Opus 4.1 (alias)",
        "description": "Alias for latest Claude Opus 4.1. Auto-updates with new releases.",
        "alias": "claude-opus-4-1-20250805",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "status": "stable"
      },
      "claude-opus-4-5-20251101": {
        "id": "claude-opus-4-5-20251101",
        "name": "Claude Opus 4.5",
        "description": "Latest flagship model with exceptional reasoning. Most capable Anthropic model for complex multi-step tasks.",
        "reasoning": true,
        "effort": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "output_tokens": 64000,
        "status": "current"
      },
      "claude-opus-4-5": {
        "id": "claude-opus-4-5",
        "name": "Claude Opus 4.5 (alias)",
        "description": "Alias for latest Claude Opus 4.5. Auto-updates with new releases.",
        "alias": "claude-opus-4-5-20251101",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "status": "stable"
      }
    }
  },
  "minimax": {
    "id": "minimax",
    "name": "MiniMax",
    "env": [
      "MINIMAX_API_KEY"
    ],
    "api": "https://api.minimax.chat/v1",
    "doc": "https://platform.minimaxi.com/document/ChatCompletion%20V2",
    "models": {
      "MiniMax-M2.5": {
        "id": "MiniMax-M2.5",
        "name": "MiniMax-M2.5",
        "description": "Latest MiniMax-M2.5 model with enhanced code understanding and reasoning",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 204800
      },
      "MiniMax-M2": {
        "id": "MiniMax-M2",
        "name": "MiniMax-M2",
        "description": "MiniMax reasoning-focused model optimized for dialogue",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      }
    }
  },
  "deepseek": {
    "id": "deepseek",
    "env": [
      "DEEPSEEK_API_KEY"
    ],
    "api": "https://api.deepseek.com",
    "name": "DeepSeek",
    "doc": "https://platform.deepseek.com/api-docs",
    "models": {
      "deepseek-chat": {
        "id": "deepseek-chat",
        "name": "DeepSeek V3.2 Chat",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "description": "Fast, efficient chat model optimized for immediate responses"
      },
      "deepseek-reasoner": {
        "id": "deepseek-reasoner",
        "name": "DeepSeek V3.2 Reasoner",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "description": "Advanced reasoning model with thinking mode and integrated tool-use"
      }
    }
  },
  "zai": {
    "id": "zai",
    "env": [
      "ZAI_API_KEY"
    ],
    "api": "https://api.z.ai/api",
    "name": "Z.AI",
    "doc": "https://docs.z.ai/guides/llm/glm-5",
    "models": {
      "glm-5": {
        "id": "glm-5",
        "name": "GLM-5",
        "description": "Z.ai flagship GLM-5 foundation model engineered for complex systems design and long-horizon agent workflows. Built for expert developers, it delivers production-grade performance on large-scale programming tasks, rivaling leading closed-source models. With advanced agentic planning, deep backend reasoning, and iterative self-correction, GLM-5 moves beyond code generation to full-system construction and autonomous execution.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "max_output_tokens": 128000,
        "capabilities": {
          "thinking": true,
          "streaming": true,
          "function_calling": true,
          "context_caching": true,
          "structured_output": true,
          "tool_streaming": true
        },
        "vtcode": {
          "variant": "ZaiGlm5",
          "constant": "Z_AI_GLM_5",
          "display": "GLM-5",
          "description": "Z.AI flagship foundation model for complex systems engineering and long-horizon tasks.",
          "efficient": false,
          "top_tier": true,
          "generation": "GLM-5",
          "doc_comment": "GLM-5 - Z.AI flagship GLM-5 model"
        }
      }
    }
  },
  "openrouter": {
    "id": "openrouter",
    "env": [
      "OPENROUTER_API_KEY"
    ],
    "api": "https://openrouter.ai/api/v1",
    "name": "OpenRouter",
    "doc": "https://openrouter.ai/models",
    "models": {
      "stepfun/step-3.5-flash:free": {
        "id": "stepfun/step-3.5-flash:free",
        "name": "Step 3.5 Flash (free)",
        "description": "Step 3.5 Flash is StepFun's most capable open-source foundation model. Built on a sparse Mixture of Experts (MoE) architecture, it selectively activates only 11B of its 196B parameters per token. It is a reasoning model that is incredibly speed efficient even at long contexts.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 256000,
        "vtcode": {
          "variant": "OpenRouterStepfunStep35FlashFree",
          "constant": "STEPFUN_STEP_3_5_FLASH_FREE",
          "vendor": "stepfun",
          "display": "Step 3.5 Flash (free)",
          "description": "Step 3.5 Flash (free) model via OpenRouter",
          "efficient": true,
          "top_tier": true,
          "generation": "Step-3.5",
          "doc_comment": "Step 3.5 Flash (free) - StepFun's most capable open-source reasoning model via OpenRouter"
        }
      },
      "anthropic/claude-haiku-4.5": {
        "id": "anthropic/claude-haiku-4.5",
        "name": "Anthropic: Claude Haiku 4.5",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "vtcode": {
          "variant": "OpenRouterAnthropicClaudeHaiku45",
          "constant": "ANTHROPIC_CLAUDE_HAIKU_4_5",
          "vendor": "anthropic",
          "display": "Claude Haiku 4.5",
          "description": "Anthropic Claude Haiku 4.5 listing",
          "efficient": true,
          "top_tier": false,
          "generation": "2025-10-15",
          "doc_comment": "Claude Haiku 4.5 - Anthropic Claude Haiku 4.5 listing"
        }
      },
      "anthropic/claude-opus-4.1": {
        "id": "anthropic/claude-opus-4.1",
        "name": "Anthropic: Claude Opus 4.1",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "image",
            "text",
            "file"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "max_output_tokens": 32000,
        "cost": {
          "input": 1.5e-05,
          "output": 7.5e-05
        },
        "vtcode": {
          "variant": "OpenRouterAnthropicClaudeOpus41",
          "constant": "ANTHROPIC_CLAUDE_OPUS_4_1",
          "vendor": "anthropic",
          "display": "Claude Opus 4.1",
          "description": "Anthropic Claude Opus 4.1 listing",
          "efficient": false,
          "top_tier": true,
          "generation": "2025-08-05",
          "doc_comment": "Claude Opus 4.1 - Anthropic Claude Opus 4.1 listing"
        }
      },
      "anthropic/claude-sonnet-4.5": {
        "id": "anthropic/claude-sonnet-4.5",
        "name": "Anthropic: Claude Sonnet 4.5",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "file"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1000000,
        "max_output_tokens": 64000,
        "cost": {
          "input": 3e-06,
          "output": 1.5e-05
        },
        "vtcode": {
          "variant": "OpenRouterAnthropicClaudeSonnet45",
          "constant": "ANTHROPIC_CLAUDE_SONNET_4_5",
          "vendor": "anthropic",
          "display": "Claude Sonnet 4.5",
          "description": "Anthropic Claude Sonnet 4.5 listing",
          "efficient": false,
          "top_tier": true,
          "generation": "2025-10-15",
          "doc_comment": "Claude Sonnet 4.5 - Anthropic Claude Sonnet 4.5 listing"
        }
      },
      "anthropic/claude-sonnet-4.6": {
        "id": "anthropic/claude-sonnet-4.6",
        "name": "Anthropic: Claude Sonnet 4.6",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "file"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1000000,
        "max_output_tokens": 128000,
        "cost": {
          "input": 3e-06,
          "output": 1.5e-05
        },
        "vtcode": {
          "variant": "OpenRouterAnthropicClaudeSonnet46",
          "constant": "ANTHROPIC_CLAUDE_SONNET_4_6",
          "vendor": "anthropic",
          "display": "Claude Sonnet 4.6",
          "description": "Anthropic Claude Sonnet 4.6 listing",
          "efficient": false,
          "top_tier": true,
          "generation": "2026-02-20",
          "doc_comment": "Claude Sonnet 4.6 - Anthropic Claude Sonnet 4.6 listing"
        }
      },
      "deepseek/deepseek-chat": {
        "id": "deepseek/deepseek-chat",
        "name": "DeepSeek V3.2 Chat",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 8192,
        "vtcode": {
          "variant": "OpenRouterDeepseekChat",
          "constant": "DEEPSEEK_CHAT",
          "vendor": "deepseek",
          "display": "DeepSeek V3.2 Chat",
          "description": "DeepSeek official chat model via OpenRouter",
          "efficient": true,
          "top_tier": true,
          "generation": "V3.2",
          "doc_comment": "DeepSeek V3.2 Chat - Official chat model via OpenRouter"
        }
      },
      "deepseek/deepseek-chat-v3.1": {
        "id": "deepseek/deepseek-chat-v3.1",
        "name": "DeepSeek: DeepSeek V3.1",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 163840,
        "max_output_tokens": 163840,
        "cost": {
          "input": 2e-07,
          "output": 8e-07
        },
        "vtcode": {
          "variant": "OpenRouterDeepSeekChatV31",
          "constant": "DEEPSEEK_CHAT_V3_1",
          "vendor": "deepseek",
          "display": "DeepSeek Chat v3.1",
          "description": "Advanced DeepSeek model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "2025-08-21",
          "doc_comment": "DeepSeek Chat v3.1 - Advanced DeepSeek model via OpenRouter"
        }
      },
      "deepseek/deepseek-r1": {
        "id": "deepseek/deepseek-r1",
        "name": "DeepSeek: R1",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 163840,
        "max_output_tokens": 163840,
        "cost": {
          "input": 4e-07,
          "output": 2e-06
        },
        "vtcode": {
          "variant": "OpenRouterDeepSeekR1",
          "constant": "DEEPSEEK_R1",
          "vendor": "deepseek",
          "display": "DeepSeek R1",
          "description": "DeepSeek R1 reasoning model with chain-of-thought",
          "efficient": false,
          "top_tier": true,
          "generation": "2025-01-20",
          "doc_comment": "DeepSeek R1 - DeepSeek R1 reasoning model with chain-of-thought"
        }
      },
      "deepseek/deepseek-reasoner": {
        "id": "deepseek/deepseek-reasoner",
        "name": "DeepSeek V3.2 Reasoner (Thinking)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 8192,
        "vtcode": {
          "variant": "OpenRouterDeepseekReasoner",
          "constant": "DEEPSEEK_REASONER",
          "vendor": "deepseek",
          "display": "DeepSeek V3.2 Reasoner",
          "description": "DeepSeek thinking mode model via OpenRouter with deliberate reasoning output",
          "efficient": false,
          "top_tier": true,
          "generation": "V3.2",
          "doc_comment": "DeepSeek V3.2 Reasoner - Thinking mode via OpenRouter"
        }
      },
      "deepseek/deepseek-v3.2": {
        "id": "deepseek/deepseek-v3.2",
        "name": "DeepSeek V3.2",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 8192,
        "vtcode": {
          "variant": "OpenRouterDeepSeekV32",
          "constant": "DEEPSEEK_V3_2",
          "vendor": "deepseek",
          "display": "DeepSeek V3.2",
          "description": "DeepSeek V3.2 model with thinking support via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "V3.2",
          "doc_comment": "DeepSeek V3.2 - Standard model with thinking support via OpenRouter"
        }
      },
      "deepseek/deepseek-v3.2-exp": {
        "id": "deepseek/deepseek-v3.2-exp",
        "name": "DeepSeek: DeepSeek V3.2 Exp",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 163840,
        "max_output_tokens": null,
        "cost": {
          "input": 2.7e-07,
          "output": 4e-07
        },
        "vtcode": {
          "variant": "OpenRouterDeepSeekV32Exp",
          "constant": "DEEPSEEK_V3_2_EXP",
          "vendor": "deepseek",
          "display": "DeepSeek V3.2 Exp",
          "description": "Experimental DeepSeek V3.2 listing",
          "efficient": false,
          "top_tier": true,
          "generation": "V3.2-Exp",
          "doc_comment": "DeepSeek V3.2 Exp - Experimental DeepSeek V3.2 listing"
        }
      },
      "deepseek/deepseek-v3.2-speciale": {
        "id": "deepseek/deepseek-v3.2-speciale",
        "name": "DeepSeek V3.2 Speciale",
        "reasoning": true,
        "tool_call": false,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 8192,
        "vtcode": {
          "variant": "OpenRouterDeepSeekV32Speciale",
          "constant": "DEEPSEEK_V3_2_SPECIALE",
          "vendor": "deepseek",
          "display": "DeepSeek V3.2 Speciale",
          "description": "DeepSeek V3.2 Speciale - Enhanced reasoning model (no tool-use)",
          "efficient": false,
          "top_tier": true,
          "generation": "V3.2",
          "doc_comment": "DeepSeek V3.2 Speciale - Enhanced reasoning with maxed-out capabilities"
        }
      },
      "google/gemini-3.1-pro-preview": {
        "id": "google/gemini-3.1-pro-preview",
        "name": "Google: Gemini 3.1 Pro Preview",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "file"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1048576,
        "vtcode": {
          "variant": "OpenRouterGoogleGemini31ProPreview",
          "constant": "GOOGLE_GEMINI_3_1_PRO_PREVIEW",
          "vendor": "google",
          "display": "Gemini 3.1 Pro Preview",
          "description": "Google Gemini 3.1 Pro model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "3.1",
          "doc_comment": "Gemini 3.1 Pro Preview - Google Gemini 3.1 Pro model via OpenRouter"
        }
      },
      "openai/gpt-5": {
        "id": "openai/gpt-5",
        "name": "OpenAI: GPT-5",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image",
            "file"
          ],
          "output": [
            "text"
          ]
        },
        "context": 400000,
        "max_output_tokens": 128000,
        "cost": {
          "input": 1.25e-06,
          "output": 1e-05
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIGpt5",
          "constant": "OPENAI_GPT_5",
          "vendor": "openai",
          "display": "OpenAI GPT-5",
          "description": "OpenAI GPT-5 model accessed through OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "2025-09-20",
          "doc_comment": "OpenAI GPT-5 - OpenAI GPT-5 model accessed through OpenRouter"
        }
      },
      "openai/gpt-5-chat": {
        "id": "openai/gpt-5-chat",
        "name": "OpenAI: GPT-5 Chat",
        "reasoning": false,
        "tool_call": false,
        "modalities": {
          "input": [
            "file",
            "image",
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 16384,
        "cost": {
          "input": 1.25e-06,
          "output": 1e-05
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIGpt5Chat",
          "constant": "OPENAI_GPT_5_CHAT",
          "vendor": "openai",
          "display": "OpenAI GPT-5 Chat",
          "description": "Chat optimised GPT-5 endpoint without tool use",
          "efficient": false,
          "top_tier": false,
          "generation": "2025-09-20",
          "doc_comment": "OpenAI GPT-5 Chat - Chat optimised GPT-5 endpoint without tool use"
        }
      },
      "openai/gpt-oss-120b": {
        "id": "openai/gpt-oss-120b",
        "name": "OpenAI: gpt-oss-120b",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "max_output_tokens": 131072,
        "cost": {
          "input": 4e-08,
          "output": 4e-07
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIGptOss120b",
          "constant": "OPENAI_GPT_OSS_120B",
          "vendor": "openai",
          "display": "OpenAI gpt-oss-120b",
          "description": "Open-weight 120B reasoning model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "OSS-120B",
          "doc_comment": "OpenAI gpt-oss-120b - Open-weight 120B reasoning model via OpenRouter"
        }
      },
      "openai/gpt-oss-120b:free": {
        "id": "openai/gpt-oss-120b:free",
        "name": "OpenAI: gpt-oss-120b (free)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "max_output_tokens": 131072,
        "cost": {
          "input": 0,
          "output": 0
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIGptOss120bFree",
          "constant": "OPENAI_GPT_OSS_120B_FREE",
          "vendor": "openai",
          "display": "OpenAI gpt-oss-120b (free)",
          "description": "Open-weight 120B reasoning model - free tier via OpenRouter",
          "efficient": true,
          "top_tier": false,
          "generation": "OSS-120B",
          "doc_comment": "OpenAI gpt-oss-120b:free - Open-weight 120B reasoning model free tier via OpenRouter"
        }
      },
      "openai/gpt-oss-20b": {
        "id": "openai/gpt-oss-20b",
        "name": "OpenAI: gpt-oss-20b",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072,
        "max_output_tokens": null,
        "cost": {
          "input": 3e-08,
          "output": 1.4e-07
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIGptOss20b",
          "constant": "OPENAI_GPT_OSS_20B",
          "vendor": "openai",
          "display": "OpenAI gpt-oss-20b",
          "description": "Open-weight 20B deployment via OpenRouter",
          "efficient": false,
          "top_tier": false,
          "generation": "OSS-20B",
          "doc_comment": "OpenAI gpt-oss-20b - Open-weight 20B deployment via OpenRouter"
        }
      },
      "qwen/qwen3-14b": {
        "id": "qwen/qwen3-14b",
        "name": "Qwen: Qwen3 14B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 40960,
        "max_output_tokens": 40960,
        "cost": {
          "input": 5e-08,
          "output": 2.2e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen314b",
          "constant": "QWEN3_14B",
          "vendor": "qwen",
          "display": "Qwen3 14B",
          "description": "Lightweight Qwen3 14B model",
          "efficient": true,
          "top_tier": false,
          "generation": "Qwen3-14B",
          "doc_comment": "Qwen3 14B - Lightweight Qwen3 14B model"
        }
      },
      "qwen/qwen3-235b-a22b": {
        "id": "qwen/qwen3-235b-a22b",
        "name": "Qwen: Qwen3 235B A22B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 40960,
        "max_output_tokens": 40960,
        "cost": {
          "input": 1.8e-07,
          "output": 5.4e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3235bA22b",
          "constant": "QWEN3_235B_A22B",
          "vendor": "qwen",
          "display": "Qwen3 235B A22B",
          "description": "Mixture-of-experts Qwen3 235B general model",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3",
          "doc_comment": "Qwen3 235B A22B - Mixture-of-experts Qwen3 235B general model"
        }
      },
      "qwen/qwen3-235b-a22b-2507": {
        "id": "qwen/qwen3-235b-a22b-2507",
        "name": "Qwen: Qwen3 235B A22B Instruct 2507",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 8e-08,
          "output": 5.5e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3235bA22b2507",
          "constant": "QWEN3_235B_A22B_2507",
          "vendor": "qwen",
          "display": "Qwen3 235B A22B Instruct 2507",
          "description": "Instruction-tuned Qwen3 235B A22B",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-2507",
          "doc_comment": "Qwen3 235B A22B Instruct 2507 - Instruction-tuned Qwen3 235B A22B"
        }
      },
      "qwen/qwen3-235b-a22b-thinking-2507": {
        "id": "qwen/qwen3-235b-a22b-thinking-2507",
        "name": "Qwen: Qwen3 235B A22B Thinking 2507",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 1.1e-07,
          "output": 6e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3235bA22bThinking2507",
          "constant": "QWEN3_235B_A22B_THINKING_2507",
          "vendor": "qwen",
          "display": "Qwen3 235B A22B Thinking 2507",
          "description": "Deliberative Qwen3 235B A22B reasoning release",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-2507",
          "doc_comment": "Qwen3 235B A22B Thinking 2507 - Deliberative Qwen3 235B A22B reasoning release"
        }
      },
      "qwen/qwen3-30b-a3b": {
        "id": "qwen/qwen3-30b-a3b",
        "name": "Qwen: Qwen3 30B A3B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 40960,
        "max_output_tokens": 40960,
        "cost": {
          "input": 6e-08,
          "output": 2.2e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen330bA3b",
          "constant": "QWEN3_30B_A3B",
          "vendor": "qwen",
          "display": "Qwen3 30B A3B",
          "description": "Active-parameter 30B Qwen3 model",
          "efficient": false,
          "top_tier": false,
          "generation": "Qwen3-30B",
          "doc_comment": "Qwen3 30B A3B - Active-parameter 30B Qwen3 model"
        }
      },
      "qwen/qwen3-30b-a3b-instruct-2507": {
        "id": "qwen/qwen3-30b-a3b-instruct-2507",
        "name": "Qwen: Qwen3 30B A3B Instruct 2507",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 8e-08,
          "output": 3.3e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen330bA3bInstruct2507",
          "constant": "QWEN3_30B_A3B_INSTRUCT_2507",
          "vendor": "qwen",
          "display": "Qwen3 30B A3B Instruct 2507",
          "description": "Instruction-tuned Qwen3 30B A3B",
          "efficient": false,
          "top_tier": false,
          "generation": "Qwen3-30B",
          "doc_comment": "Qwen3 30B A3B Instruct 2507 - Instruction-tuned Qwen3 30B A3B"
        }
      },
      "qwen/qwen3-30b-a3b-thinking-2507": {
        "id": "qwen/qwen3-30b-a3b-thinking-2507",
        "name": "Qwen: Qwen3 30B A3B Thinking 2507",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 8e-08,
          "output": 2.9e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen330bA3bThinking2507",
          "constant": "QWEN3_30B_A3B_THINKING_2507",
          "vendor": "qwen",
          "display": "Qwen3 30B A3B Thinking 2507",
          "description": "Deliberative Qwen3 30B A3B release",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-30B",
          "doc_comment": "Qwen3 30B A3B Thinking 2507 - Deliberative Qwen3 30B A3B release"
        }
      },
      "qwen/qwen3-32b": {
        "id": "qwen/qwen3-32b",
        "name": "Qwen: Qwen3 32B",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 40960,
        "max_output_tokens": 40960,
        "cost": {
          "input": 5e-08,
          "output": 2e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen332b",
          "constant": "QWEN3_32B",
          "vendor": "qwen",
          "display": "Qwen3 32B",
          "description": "Dense 32B Qwen3 deployment",
          "efficient": false,
          "top_tier": false,
          "generation": "Qwen3-32B",
          "doc_comment": "Qwen3 32B - Dense 32B Qwen3 deployment"
        }
      },
      "qwen/qwen3-8b": {
        "id": "qwen/qwen3-8b",
        "name": "Qwen: Qwen3 8B",
        "reasoning": true,
        "tool_call": false,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 20000,
        "cost": {
          "input": 3.5e-08,
          "output": 1.38e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen38b",
          "constant": "QWEN3_8B",
          "vendor": "qwen",
          "display": "Qwen3 8B",
          "description": "Compact Qwen3 8B deployment",
          "efficient": true,
          "top_tier": false,
          "generation": "Qwen3-8B",
          "doc_comment": "Qwen3 8B - Compact Qwen3 8B deployment"
        }
      },
      "qwen/qwen3-coder": {
        "id": "qwen/qwen3-coder",
        "name": "Qwen: Qwen3 Coder 480B A35B",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 2.2e-07,
          "output": 9.5e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3Coder",
          "constant": "QWEN3_CODER",
          "vendor": "qwen",
          "display": "Qwen3 Coder",
          "description": "Qwen3-based coding model tuned for IDE workflows",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-Coder",
          "doc_comment": "Qwen3 Coder - Qwen3-based coding model tuned for IDE workflows"
        }
      },
      "qwen/qwen3-coder-30b-a3b-instruct": {
        "id": "qwen/qwen3-coder-30b-a3b-instruct",
        "name": "Qwen: Qwen3 Coder 30B A3B Instruct",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 6e-08,
          "output": 2.5e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3Coder30bA3bInstruct",
          "constant": "QWEN3_CODER_30B_A3B_INSTRUCT",
          "vendor": "qwen",
          "display": "Qwen3 Coder 30B A3B Instruct",
          "description": "Large Mixture-of-Experts coding deployment",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-Coder",
          "doc_comment": "Qwen3 Coder 30B A3B Instruct - Large Mixture-of-Experts coding deployment"
        }
      },
      "qwen/qwen3-coder-next": {
        "id": "qwen/qwen3-coder-next",
        "name": "Qwen: Qwen3 Coder Next",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 2.2e-07,
          "output": 9.5e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3CoderNext",
          "constant": "QWEN3_CODER_NEXT",
          "vendor": "qwen",
          "display": "Qwen3 Coder Next",
          "description": "Next-generation Qwen3 coding model with enhanced reasoning",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-Coder",
          "doc_comment": "Qwen3 Coder Next - Next-generation Qwen3 coding model with enhanced reasoning"
        }
      },
      "qwen/qwen3-coder-flash": {
        "id": "qwen/qwen3-coder-flash",
        "name": "Qwen: Qwen3 Coder Flash",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 65536,
        "cost": {
          "input": 3e-07,
          "output": 1.5e-06
        },
        "vtcode": {
          "variant": "OpenRouterQwen3CoderFlash",
          "constant": "QWEN3_CODER_FLASH",
          "vendor": "qwen",
          "display": "Qwen3 Coder Flash",
          "description": "Latency optimised Qwen3 coding model",
          "efficient": true,
          "top_tier": false,
          "generation": "Qwen3-Coder",
          "doc_comment": "Qwen3 Coder Flash - Latency optimised Qwen3 coding model"
        }
      },
      "qwen/qwen3-coder-plus": {
        "id": "qwen/qwen3-coder-plus",
        "name": "Qwen: Qwen3 Coder Plus",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 65536,
        "cost": {
          "input": 1e-06,
          "output": 5e-06
        },
        "vtcode": {
          "variant": "OpenRouterQwen3CoderPlus",
          "constant": "QWEN3_CODER_PLUS",
          "vendor": "qwen",
          "display": "Qwen3 Coder Plus",
          "description": "Premium Qwen3 coding model with long context",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-Coder",
          "doc_comment": "Qwen3 Coder Plus - Premium Qwen3 coding model with long context"
        }
      },
      "qwen/qwen3-max": {
        "id": "qwen/qwen3-max",
        "name": "Qwen: Qwen3 Max",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 256000,
        "max_output_tokens": 32768,
        "cost": {
          "input": 1.2e-06,
          "output": 6e-06
        },
        "vtcode": {
          "variant": "OpenRouterQwen3Max",
          "constant": "QWEN3_MAX",
          "vendor": "qwen",
          "display": "Qwen3 Max",
          "description": "Flagship Qwen3 mixture for general reasoning",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3",
          "doc_comment": "Qwen3 Max - Flagship Qwen3 mixture for general reasoning"
        }
      },
      "qwen/qwen3-next-80b-a3b-instruct": {
        "id": "qwen/qwen3-next-80b-a3b-instruct",
        "name": "Qwen: Qwen3 Next 80B A3B Instruct",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": 262144,
        "cost": {
          "input": 1e-07,
          "output": 8e-07
        },
        "vtcode": {
          "variant": "OpenRouterQwen3Next80bA3bInstruct",
          "constant": "QWEN3_NEXT_80B_A3B_INSTRUCT",
          "vendor": "qwen",
          "display": "Qwen3 Next 80B A3B Instruct",
          "description": "Next-generation Qwen3 instruction model",
          "efficient": false,
          "top_tier": false,
          "generation": "Qwen3-Next",
          "doc_comment": "Qwen3 Next 80B A3B Instruct - Next-generation Qwen3 instruction model"
        }
      },
      "qwen/qwen3-next-80b-a3b-thinking": {
        "id": "qwen/qwen3-next-80b-a3b-thinking",
        "name": "Qwen: Qwen3 Next 80B A3B Thinking",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144,
        "max_output_tokens": null,
        "cost": {
          "input": 1.4e-07,
          "output": 1.2e-06
        },
        "vtcode": {
          "variant": "OpenRouterQwen3Next80bA3bThinking",
          "constant": "QWEN3_NEXT_80B_A3B_THINKING",
          "vendor": "qwen",
          "display": "Qwen3 Next 80B A3B Thinking",
          "description": "Next-generation Qwen3 reasoning release",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3-Next",
          "doc_comment": "Qwen3 Next 80B A3B Thinking - Next-generation Qwen3 reasoning release"
        }
      },
      "qwen/qwen3.5-plus-02-15": {
        "id": "qwen/qwen3.5-plus-02-15",
        "name": "Qwen: Qwen3.5-397B-A17B",
        "description": "The Qwen3.5 native vision-language series Plus models are built on a hybrid architecture that integrates linear attention mechanisms with sparse mixture-of-experts models, achieving higher inference efficiency. In a variety of task evaluations, the 3.5 series consistently demonstrates performance on par with state-of-the-art leading models. Compared to the 3 series, these models show a leap forward in both pure-text and multimodal capabilities.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text",
            "image"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1000000,
        "max_output_tokens": 256000,
        "cost": {
          "input": 5e-07,
          "output": 2.5e-06
        },
        "vtcode": {
          "variant": "OpenRouterQwen35Plus0215",
          "constant": "QWEN3_5_PLUS_02_15",
          "vendor": "qwen",
          "display": "Qwen3.5-397B-A17B",
          "description": "Qwen3.5 Plus with hybrid linear attention and sparse MoE architecture, 1M context",
          "efficient": false,
          "top_tier": true,
          "generation": "Qwen3.5-Plus",
          "doc_comment": "Qwen3.5-397B-A17B - Native vision-language model with linear attention and sparse MoE, 1M context window"
        }
      },
      "amazon/nova-2-lite-v1": {
        "id": "amazon/nova-2-lite-v1",
        "name": "Amazon: Nova 2 Lite",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 307200,
        "max_output_tokens": 5000,
        "cost": {
          "input": 8e-07,
          "output": 2.4e-06
        },
        "vtcode": {
          "variant": "OpenRouterAmazonNova2LiteV1",
          "constant": "AMAZON_NOVA_2_LITE_V1",
          "vendor": "amazon",
          "display": "Amazon Nova 2 Lite",
          "description": "Amazon Nova 2 Lite model via OpenRouter",
          "efficient": true,
          "top_tier": false,
          "generation": "Nova-2",
          "doc_comment": "Amazon Nova 2 Lite - Amazon Nova 2 Lite model via OpenRouter"
        }
      },
      "mistralai/mistral-large-2512": {
        "id": "mistralai/mistral-large-2512",
        "name": "Mistral: Mistral Large 3 2512",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 128000,
        "max_output_tokens": 8192,
        "cost": {
          "input": 2e-06,
          "output": 6e-06
        },
        "vtcode": {
          "variant": "OpenRouterMistralaiMistralLarge2512",
          "constant": "MISTRALAI_MISTRAL_LARGE_2512",
          "vendor": "mistralai",
          "display": "Mistral Large 3 2512",
          "description": "Mistral Large 3 2512 model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "Mistral-Large-3",
          "doc_comment": "Mistral Large 3 2512 - Mistral Large 3 2512 model via OpenRouter"
        }
      },
      "nex-agi/deepseek-v3.1-nex-n1": {
        "id": "nex-agi/deepseek-v3.1-nex-n1",
        "name": "Nex AGI: DeepSeek V3.1 Nex N1",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 163840,
        "max_output_tokens": 163840,
        "cost": {
          "input": 2e-07,
          "output": 8e-07
        },
        "vtcode": {
          "variant": "OpenRouterNexAgiDeepseekV31NexN1",
          "constant": "NEX_AGI_DEEPSEEK_V3_1_NEX_N1",
          "vendor": "nex-agi",
          "display": "DeepSeek V3.1 Nex N1",
          "description": "Nex AGI DeepSeek V3.1 Nex N1 model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "V3.1-Nex",
          "doc_comment": "DeepSeek V3.1 Nex N1 - Nex AGI DeepSeek V3.1 Nex N1 model via OpenRouter"
        }
      },
      "openai/o1-pro": {
        "id": "openai/o1-pro",
        "name": "OpenAI: o1-pro",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 200000,
        "max_output_tokens": 10000,
        "cost": {
          "input": 1.5e-05,
          "output": 6e-05
        },
        "vtcode": {
          "variant": "OpenRouterOpenAIO1Pro",
          "constant": "OPENAI_O1_PRO",
          "vendor": "openai",
          "display": "OpenAI o1-pro",
          "description": "OpenAI o1-pro advanced reasoning model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "o1-series",
          "doc_comment": "OpenAI o1-pro - OpenAI o1-pro advanced reasoning model via OpenRouter"
        }
      },
      "z-ai/glm-5": {
        "id": "z-ai/glm-5",
        "name": "Z.AI: GLM-5",
        "description": "Z.ai's flagship open-source foundation model engineered for complex systems design and long-horizon agent workflows. Built for expert developers, it delivers production-grade performance on large-scale programming tasks, rivaling leading closed-source models. With advanced agentic planning, deep backend reasoning, and iterative self-correction, GLM-5 moves beyond code generation to full-system construction and autonomous execution.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 202752,
        "vtcode": {
          "variant": "OpenRouterZaiGlm5",
          "constant": "Z_AI_GLM_5",
          "vendor": "zai",
          "display": "GLM-5",
          "description": "Z.ai flagship GLM-5 model via OpenRouter",
          "efficient": false,
          "top_tier": true,
          "generation": "GLM-5",
          "doc_comment": "GLM-5 - Z.AI GLM-5 flagship foundation model via OpenRouter"
        }
      }
    },
    "default_model": "z-ai/glm-5"
  },
  "ollama": {
    "id": "ollama",
    "env": [
      "OLLAMA_API_KEY (optional)"
    ],
    "api": "http://localhost:11434",
    "name": "Ollama",
    "doc": "https://github.com/ollama/ollama/blob/main/docs/api.md",
    "models": {
      "gpt-oss:20b": {
        "id": "gpt-oss:20b",
        "name": "GPT-OSS 20B (local)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "gpt-oss:20b-cloud": {
        "id": "gpt-oss:20b-cloud",
        "name": "GPT-OSS 20B (cloud)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "gpt-oss:120b-cloud": {
        "id": "gpt-oss:120b-cloud",
        "name": "GPT-OSS 120B (cloud)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "qwen3:1.7b": {
        "id": "qwen3:1.7b",
        "name": "Qwen3 1.7B (local)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 32768
      },
      "qwen3-coder-next:cloud": {
        "id": "qwen3-coder-next:cloud",
        "name": "Qwen3-Coder-Next (cloud)",
        "description": "Agentically-trained coding model built on Qwen3-Next-80B-A3B-Base with hybrid attention + MoE, optimized for efficient tool-use and non-thinking responses.",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 262144
      },
      "deepseek-v3.1:671b-cloud": {
        "id": "deepseek-v3.1:671b-cloud",
        "name": "DeepSeek V3.1 671B (cloud)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "qwen3-coder:480b-cloud": {
        "id": "qwen3-coder:480b-cloud",
        "name": "Qwen3 Coder 480B (cloud)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "minimax-m2:cloud": {
        "id": "minimax-m2:cloud",
        "name": "MiniMax-M2 (cloud)",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "glm-4.7:cloud": {
        "id": "glm-4.7:cloud",
        "name": "GLM 4.7 (cloud)",
        "description": "Advancing the Coding Capability",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "minimax-m2.5:cloud": {
        "id": "minimax-m2.5:cloud",
        "name": "MiniMax-M2.5 (cloud)",
        "description": "Exceptional multilingual capabilities to elevate code engineering",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "gemini-3-flash-preview:cloud": {
        "id": "gemini-3-flash-preview:cloud",
        "name": "Gemini 3 Flash Preview (cloud)",
        "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.",
        "reasoning": true,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 1000000
      }
    }
  },
  "lmstudio": {
    "id": "lmstudio",
    "env": [
      "LMSTUDIO_API_KEY (optional)",
      "LMSTUDIO_BASE_URL (optional)"
    ],
    "api": "http://localhost:1234/v1",
    "name": "LM Studio",
    "doc": "https://lmstudio.ai/docs/developer/openai-compat",
    "models": {
      "lmstudio-community/meta-llama-3-8b-instruct": {
        "id": "lmstudio-community/meta-llama-3-8b-instruct",
        "name": "Meta Llama 3 8B (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 8192
      },
      "lmstudio-community/meta-llama-3.1-8b-instruct": {
        "id": "lmstudio-community/meta-llama-3.1-8b-instruct",
        "name": "Meta Llama 3.1 8B (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 131072
      },
      "lmstudio-community/qwen2.5-7b-instruct": {
        "id": "lmstudio-community/qwen2.5-7b-instruct",
        "name": "Qwen2.5 7B (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 32768
      },
      "lmstudio-community/gemma-2-2b-it": {
        "id": "lmstudio-community/gemma-2-2b-it",
        "name": "Gemma 2 2B (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 8192
      },
      "lmstudio-community/gemma-2-9b-it": {
        "id": "lmstudio-community/gemma-2-9b-it",
        "name": "Gemma 2 9B (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 8192
      },
      "lmstudio-community/phi-3.1-mini-4k-instruct": {
        "id": "lmstudio-community/phi-3.1-mini-4k-instruct",
        "name": "Phi-3.1 Mini 4K (local)",
        "reasoning": false,
        "tool_call": true,
        "modalities": {
          "input": [
            "text"
          ],
          "output": [
            "text"
          ]
        },
        "context": 4096
      }
    }
  }
}