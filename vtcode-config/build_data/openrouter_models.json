{
  "id": "openrouter",
  "env": [
    "OPENROUTER_API_KEY"
  ],
  "api": "https://openrouter.ai/api/v1",
  "name": "OpenRouter",
  "doc": "https://openrouter.ai/models",
  "models": {
    "amazon/nova-2-lite-v1": {
      "id": "amazon/nova-2-lite-v1",
      "name": "Amazon: Nova 2 Lite",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 307200,
      "max_output_tokens": 5000,
      "cost": {
        "input": 8e-07,
        "output": 2.4e-06
      },
      "vtcode": {
        "variant": "OpenRouterAmazonNova2LiteV1",
        "constant": "AMAZON_NOVA_2_LITE_V1",
        "vendor": "amazon",
        "display": "Amazon Nova 2 Lite",
        "description": "Amazon Nova 2 Lite model via OpenRouter",
        "efficient": true,
        "top_tier": false,
        "generation": "Nova-2",
        "doc_comment": "Amazon Nova 2 Lite - Amazon Nova 2 Lite model via OpenRouter"
      }
    },
    "mistralai/mistral-large-2512": {
      "id": "mistralai/mistral-large-2512",
      "name": "Mistral: Mistral Large 3 2512",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 8192,
      "cost": {
        "input": 2e-06,
        "output": 6e-06
      },
      "vtcode": {
        "variant": "OpenRouterMistralaiMistralLarge2512",
        "constant": "MISTRALAI_MISTRAL_LARGE_2512",
        "vendor": "mistralai",
        "display": "Mistral Large 3 2512",
        "description": "Mistral Large 3 2512 model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "Mistral-Large-3",
        "doc_comment": "Mistral Large 3 2512 - Mistral Large 3 2512 model via OpenRouter"
      }
    },
    "google/gemini-3.1-pro-preview": {
      "id": "google/gemini-3.1-pro-preview",
      "name": "Google: Gemini 3.1 Pro Preview",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text",
          "image",
          "file"
        ],
        "output": [
          "text"
        ]
      },
      "context": 1048576,
      "vtcode": {
        "variant": "OpenRouterGoogleGemini31ProPreview",
        "constant": "GOOGLE_GEMINI_3_1_PRO_PREVIEW",
        "vendor": "google",
        "display": "Gemini 3.1 Pro Preview",
        "description": "Google Gemini 3.1 Pro model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "3.1",
        "doc_comment": "Gemini 3.1 Pro Preview - Google Gemini 3.1 Pro model via OpenRouter"
      }
    },
    "stepfun/step-3.5-flash:free": {
      "id": "stepfun/step-3.5-flash:free",
      "name": "Step 3.5 Flash (free)",
      "description": "Step 3.5 Flash is StepFun's most capable open-source foundation model. Built on a sparse Mixture of Experts (MoE) architecture, it selectively activates only 11B of its 196B parameters per token. It is a reasoning model that is incredibly speed efficient even at long contexts.",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 256000,
      "vtcode": {
        "variant": "OpenRouterStepfunStep35FlashFree",
        "constant": "STEPFUN_STEP_3_5_FLASH_FREE",
        "vendor": "stepfun",
        "display": "Step 3.5 Flash (free)",
        "description": "Step 3.5 Flash (free) model via OpenRouter",
        "efficient": true,
        "top_tier": true,
        "generation": "Step-3.5",
        "doc_comment": "Step 3.5 Flash (free) - StepFun's most capable open-source reasoning model via OpenRouter"
      }
    },
    "anthropic/claude-haiku-4.5": {
      "id": "anthropic/claude-haiku-4.5",
      "name": "Anthropic: Claude Haiku 4.5",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 200000,
      "vtcode": {
        "variant": "OpenRouterAnthropicClaudeHaiku45",
        "constant": "ANTHROPIC_CLAUDE_HAIKU_4_5",
        "vendor": "anthropic",
        "display": "Claude Haiku 4.5",
        "description": "Anthropic Claude Haiku 4.5 listing",
        "efficient": true,
        "top_tier": false,
        "generation": "2025-10-15",
        "doc_comment": "Claude Haiku 4.5 - Anthropic Claude Haiku 4.5 listing"
      }
    },
    "nex-agi/deepseek-v3.1-nex-n1": {
      "id": "nex-agi/deepseek-v3.1-nex-n1",
      "name": "Nex AGI: DeepSeek V3.1 Nex N1",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 163840,
      "max_output_tokens": 163840,
      "cost": {
        "input": 2e-07,
        "output": 8e-07
      },
      "vtcode": {
        "variant": "OpenRouterNexAgiDeepseekV31NexN1",
        "constant": "NEX_AGI_DEEPSEEK_V3_1_NEX_N1",
        "vendor": "nex-agi",
        "display": "DeepSeek V3.1 Nex N1",
        "description": "Nex AGI DeepSeek V3.1 Nex N1 model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "V3.1-Nex",
        "doc_comment": "DeepSeek V3.1 Nex N1 - Nex AGI DeepSeek V3.1 Nex N1 model via OpenRouter"
      }
    },
    "anthropic/claude-opus-4.1": {
      "id": "anthropic/claude-opus-4.1",
      "name": "Anthropic: Claude Opus 4.1",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "image",
          "text",
          "file"
        ],
        "output": [
          "text"
        ]
      },
      "context": 200000,
      "max_output_tokens": 32000,
      "cost": {
        "input": 1.5e-05,
        "output": 7.5e-05
      },
      "vtcode": {
        "variant": "OpenRouterAnthropicClaudeOpus41",
        "constant": "ANTHROPIC_CLAUDE_OPUS_4_1",
        "vendor": "anthropic",
        "display": "Claude Opus 4.1",
        "description": "Anthropic Claude Opus 4.1 listing",
        "efficient": false,
        "top_tier": true,
        "generation": "2025-08-05",
        "doc_comment": "Claude Opus 4.1 - Anthropic Claude Opus 4.1 listing"
      }
    },
    "anthropic/claude-sonnet-4.5": {
      "id": "anthropic/claude-sonnet-4.5",
      "name": "Anthropic: Claude Sonnet 4.5",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text",
          "image",
          "file"
        ],
        "output": [
          "text"
        ]
      },
      "context": 1000000,
      "max_output_tokens": 64000,
      "cost": {
        "input": 3e-06,
        "output": 1.5e-05
      },
      "vtcode": {
        "variant": "OpenRouterAnthropicClaudeSonnet45",
        "constant": "ANTHROPIC_CLAUDE_SONNET_4_5",
        "vendor": "anthropic",
        "display": "Claude Sonnet 4.5",
        "description": "Anthropic Claude Sonnet 4.5 listing",
        "efficient": false,
        "top_tier": true,
        "generation": "2025-10-15",
        "doc_comment": "Claude Sonnet 4.5 - Anthropic Claude Sonnet 4.5 listing"
      }
    },
    "anthropic/claude-sonnet-4.6": {
      "id": "anthropic/claude-sonnet-4.6",
      "name": "Anthropic: Claude Sonnet 4.6",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text",
          "image",
          "file"
        ],
        "output": [
          "text"
        ]
      },
      "context": 1000000,
      "max_output_tokens": 128000,
      "cost": {
        "input": 3e-06,
        "output": 1.5e-05
      },
      "vtcode": {
        "variant": "OpenRouterAnthropicClaudeSonnet46",
        "constant": "ANTHROPIC_CLAUDE_SONNET_4_6",
        "vendor": "anthropic",
        "display": "Claude Sonnet 4.6",
        "description": "Anthropic Claude Sonnet 4.6 listing",
        "efficient": false,
        "top_tier": true,
        "generation": "2026-02-20",
        "doc_comment": "Claude Sonnet 4.6 - Anthropic Claude Sonnet 4.6 listing"
      }
    },
    "deepseek/deepseek-chat": {
      "id": "deepseek/deepseek-chat",
      "name": "DeepSeek: DeepSeek V3.2 Chat",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 8192,
      "cost": {
        "input": 2.8e-07,
        "output": 1.1e-06
      },
      "vtcode": {
        "variant": "OpenRouterDeepseekChat",
        "constant": "DEEPSEEK_CHAT",
        "vendor": "deepseek",
        "display": "DeepSeek V3.2 Chat",
        "description": "DeepSeek official chat model via OpenRouter",
        "efficient": true,
        "top_tier": true,
        "generation": "V3.2",
        "doc_comment": "DeepSeek V3.2 Chat - Official chat model via OpenRouter"
      }
    },
    "deepseek/deepseek-chat-v3.1": {
      "id": "deepseek/deepseek-chat-v3.1",
      "name": "DeepSeek: DeepSeek V3.1",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 163840,
      "max_output_tokens": 163840,
      "cost": {
        "input": 2e-07,
        "output": 8e-07
      },
      "vtcode": {
        "variant": "OpenRouterDeepSeekChatV31",
        "constant": "DEEPSEEK_CHAT_V3_1",
        "vendor": "deepseek",
        "display": "DeepSeek Chat v3.1",
        "description": "Advanced DeepSeek model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "2025-08-21",
        "doc_comment": "DeepSeek Chat v3.1 - Advanced DeepSeek model via OpenRouter"
      }
    },
    "deepseek/deepseek-r1": {
      "id": "deepseek/deepseek-r1",
      "name": "DeepSeek: R1",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 163840,
      "max_output_tokens": 163840,
      "cost": {
        "input": 4e-07,
        "output": 2e-06
      },
      "vtcode": {
        "variant": "OpenRouterDeepSeekR1",
        "constant": "DEEPSEEK_R1",
        "vendor": "deepseek",
        "display": "DeepSeek R1",
        "description": "DeepSeek R1 reasoning model with chain-of-thought",
        "efficient": false,
        "top_tier": true,
        "generation": "2025-01-20",
        "doc_comment": "DeepSeek R1 - DeepSeek R1 reasoning model with chain-of-thought"
      }
    },
    "deepseek/deepseek-reasoner": {
      "id": "deepseek/deepseek-reasoner",
      "name": "DeepSeek: DeepSeek V3.2 Reasoner (Thinking)",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 8192,
      "cost": {
        "input": 5.5e-06,
        "output": 2.2e-05
      },
      "vtcode": {
        "variant": "OpenRouterDeepseekReasoner",
        "constant": "DEEPSEEK_REASONER",
        "vendor": "deepseek",
        "display": "DeepSeek V3.2 Reasoner",
        "description": "DeepSeek thinking mode model via OpenRouter with deliberate reasoning output",
        "efficient": false,
        "top_tier": true,
        "generation": "V3.2",
        "doc_comment": "DeepSeek V3.2 Reasoner - Thinking mode via OpenRouter"
      }
    },
    "deepseek/deepseek-v3.2": {
      "id": "deepseek/deepseek-v3.2",
      "name": "DeepSeek: DeepSeek V3.2",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 8192,
      "cost": {
        "input": 2.8e-07,
        "output": 1.1e-06
      },
      "vtcode": {
        "variant": "OpenRouterDeepSeekV32",
        "constant": "DEEPSEEK_V3_2",
        "vendor": "deepseek",
        "display": "DeepSeek V3.2",
        "description": "DeepSeek V3.2 model with thinking support via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "V3.2",
        "doc_comment": "DeepSeek V3.2 - Standard model with thinking support via OpenRouter"
      }
    },
    "deepseek/deepseek-v3.2-exp": {
      "id": "deepseek/deepseek-v3.2-exp",
      "name": "DeepSeek: DeepSeek V3.2 Exp",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 163840,
      "max_output_tokens": null,
      "cost": {
        "input": 2.7e-07,
        "output": 4e-07
      },
      "vtcode": {
        "variant": "OpenRouterDeepSeekV32Exp",
        "constant": "DEEPSEEK_V3_2_EXP",
        "vendor": "deepseek",
        "display": "DeepSeek V3.2 Exp",
        "description": "Experimental DeepSeek V3.2 listing",
        "efficient": false,
        "top_tier": true,
        "generation": "V3.2-Exp",
        "doc_comment": "DeepSeek V3.2 Exp - Experimental DeepSeek V3.2 listing"
      }
    },
    "deepseek/deepseek-v3.2-speciale": {
      "id": "deepseek/deepseek-v3.2-speciale",
      "name": "DeepSeek: DeepSeek V3.2 Speciale",
      "reasoning": true,
      "tool_call": false,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 8192,
      "cost": {
        "input": 5.5e-06,
        "output": 2.2e-05
      },
      "vtcode": {
        "variant": "OpenRouterDeepSeekV32Speciale",
        "constant": "DEEPSEEK_V3_2_SPECIALE",
        "vendor": "deepseek",
        "display": "DeepSeek V3.2 Speciale",
        "description": "DeepSeek V3.2 Speciale - Enhanced reasoning model (no tool-use)",
        "efficient": false,
        "top_tier": true,
        "generation": "V3.2",
        "doc_comment": "DeepSeek V3.2 Speciale - Enhanced reasoning with maxed-out capabilities"
      }
    },
    "openai/o1-pro": {
      "id": "openai/o1-pro",
      "name": "OpenAI: o1-pro",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 200000,
      "max_output_tokens": 10000,
      "cost": {
        "input": 1.5e-05,
        "output": 6e-05
      },
      "vtcode": {
        "variant": "OpenRouterOpenAIO1Pro",
        "constant": "OPENAI_O1_PRO",
        "vendor": "openai",
        "display": "OpenAI o1-pro",
        "description": "OpenAI o1-pro advanced reasoning model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "o1-series",
        "doc_comment": "OpenAI o1-pro - OpenAI o1-pro advanced reasoning model via OpenRouter"
      }
    },
    "openai/gpt-5": {
      "id": "openai/gpt-5",
      "name": "OpenAI: GPT-5",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text",
          "image",
          "file"
        ],
        "output": [
          "text"
        ]
      },
      "context": 400000,
      "max_output_tokens": 128000,
      "cost": {
        "input": 1.25e-06,
        "output": 1e-05
      },
      "vtcode": {
        "variant": "OpenRouterOpenAIGpt5",
        "constant": "OPENAI_GPT_5",
        "vendor": "openai",
        "display": "OpenAI GPT-5",
        "description": "OpenAI GPT-5 model accessed through OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "2025-09-20",
        "doc_comment": "OpenAI GPT-5 - OpenAI GPT-5 model accessed through OpenRouter"
      }
    },
    "openai/gpt-5-chat": {
      "id": "openai/gpt-5-chat",
      "name": "OpenAI: GPT-5 Chat",
      "reasoning": false,
      "tool_call": false,
      "modalities": {
        "input": [
          "file",
          "image",
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 16384,
      "cost": {
        "input": 1.25e-06,
        "output": 1e-05
      },
      "vtcode": {
        "variant": "OpenRouterOpenAIGpt5Chat",
        "constant": "OPENAI_GPT_5_CHAT",
        "vendor": "openai",
        "display": "OpenAI GPT-5 Chat",
        "description": "Chat optimised GPT-5 endpoint without tool use",
        "efficient": false,
        "top_tier": false,
        "generation": "2025-09-20",
        "doc_comment": "OpenAI GPT-5 Chat - Chat optimised GPT-5 endpoint without tool use"
      }
    },
    "openai/gpt-oss-120b": {
      "id": "openai/gpt-oss-120b",
      "name": "OpenAI: gpt-oss-120b",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 131072,
      "max_output_tokens": 131072,
      "cost": {
        "input": 4e-08,
        "output": 4e-07
      },
      "vtcode": {
        "variant": "OpenRouterOpenAIGptOss120b",
        "constant": "OPENAI_GPT_OSS_120B",
        "vendor": "openai",
        "display": "OpenAI gpt-oss-120b",
        "description": "Open-weight 120B reasoning model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "OSS-120B",
        "doc_comment": "OpenAI gpt-oss-120b - Open-weight 120B reasoning model via OpenRouter"
      }
    },
    "openai/gpt-oss-20b": {
      "id": "openai/gpt-oss-20b",
      "name": "OpenAI: gpt-oss-20b",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 131072,
      "max_output_tokens": null,
      "cost": {
        "input": 3e-08,
        "output": 1.4e-07
      },
      "vtcode": {
        "variant": "OpenRouterOpenAIGptOss20b",
        "constant": "OPENAI_GPT_OSS_20B",
        "vendor": "openai",
        "display": "OpenAI gpt-oss-20b",
        "description": "Open-weight 20B deployment via OpenRouter",
        "efficient": false,
        "top_tier": false,
        "generation": "OSS-20B",
        "doc_comment": "OpenAI gpt-oss-20b - Open-weight 20B deployment via OpenRouter"
      }
    },
    "qwen/qwen3-14b": {
      "id": "qwen/qwen3-14b",
      "name": "Qwen: Qwen3 14B",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 40960,
      "max_output_tokens": 40960,
      "cost": {
        "input": 5e-08,
        "output": 2.2e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen314b",
        "constant": "QWEN3_14B",
        "vendor": "qwen",
        "display": "Qwen3 14B",
        "description": "Lightweight Qwen3 14B model",
        "efficient": true,
        "top_tier": false,
        "generation": "Qwen3-14B",
        "doc_comment": "Qwen3 14B - Lightweight Qwen3 14B model"
      }
    },
    "qwen/qwen3-235b-a22b": {
      "id": "qwen/qwen3-235b-a22b",
      "name": "Qwen: Qwen3 235B A22B",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 40960,
      "max_output_tokens": 40960,
      "cost": {
        "input": 1.8e-07,
        "output": 5.4e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3235bA22b",
        "constant": "QWEN3_235B_A22B",
        "vendor": "qwen",
        "display": "Qwen3 235B A22B",
        "description": "Mixture-of-experts Qwen3 235B general model",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3",
        "doc_comment": "Qwen3 235B A22B - Mixture-of-experts Qwen3 235B general model"
      }
    },
    "qwen/qwen3-235b-a22b-2507": {
      "id": "qwen/qwen3-235b-a22b-2507",
      "name": "Qwen: Qwen3 235B A22B Instruct 2507",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 8e-08,
        "output": 5.5e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3235bA22b2507",
        "constant": "QWEN3_235B_A22B_2507",
        "vendor": "qwen",
        "display": "Qwen3 235B A22B Instruct 2507",
        "description": "Instruction-tuned Qwen3 235B A22B",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-2507",
        "doc_comment": "Qwen3 235B A22B Instruct 2507 - Instruction-tuned Qwen3 235B A22B"
      }
    },
    "qwen/qwen3-235b-a22b-thinking-2507": {
      "id": "qwen/qwen3-235b-a22b-thinking-2507",
      "name": "Qwen: Qwen3 235B A22B Thinking 2507",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 1.1e-07,
        "output": 6e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3235bA22bThinking2507",
        "constant": "QWEN3_235B_A22B_THINKING_2507",
        "vendor": "qwen",
        "display": "Qwen3 235B A22B Thinking 2507",
        "description": "Deliberative Qwen3 235B A22B reasoning release",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-2507",
        "doc_comment": "Qwen3 235B A22B Thinking 2507 - Deliberative Qwen3 235B A22B reasoning release"
      }
    },
    "qwen/qwen3-30b-a3b": {
      "id": "qwen/qwen3-30b-a3b",
      "name": "Qwen: Qwen3 30B A3B",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 40960,
      "max_output_tokens": 40960,
      "cost": {
        "input": 6e-08,
        "output": 2.2e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen330bA3b",
        "constant": "QWEN3_30B_A3B",
        "vendor": "qwen",
        "display": "Qwen3 30B A3B",
        "description": "Active-parameter 30B Qwen3 model",
        "efficient": false,
        "top_tier": false,
        "generation": "Qwen3-30B",
        "doc_comment": "Qwen3 30B A3B - Active-parameter 30B Qwen3 model"
      }
    },
    "qwen/qwen3-30b-a3b-instruct-2507": {
      "id": "qwen/qwen3-30b-a3b-instruct-2507",
      "name": "Qwen: Qwen3 30B A3B Instruct 2507",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 8e-08,
        "output": 3.3e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen330bA3bInstruct2507",
        "constant": "QWEN3_30B_A3B_INSTRUCT_2507",
        "vendor": "qwen",
        "display": "Qwen3 30B A3B Instruct 2507",
        "description": "Instruction-tuned Qwen3 30B A3B",
        "efficient": false,
        "top_tier": false,
        "generation": "Qwen3-30B",
        "doc_comment": "Qwen3 30B A3B Instruct 2507 - Instruction-tuned Qwen3 30B A3B"
      }
    },
    "qwen/qwen3-30b-a3b-thinking-2507": {
      "id": "qwen/qwen3-30b-a3b-thinking-2507",
      "name": "Qwen: Qwen3 30B A3B Thinking 2507",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 8e-08,
        "output": 2.9e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen330bA3bThinking2507",
        "constant": "QWEN3_30B_A3B_THINKING_2507",
        "vendor": "qwen",
        "display": "Qwen3 30B A3B Thinking 2507",
        "description": "Deliberative Qwen3 30B A3B release",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-30B",
        "doc_comment": "Qwen3 30B A3B Thinking 2507 - Deliberative Qwen3 30B A3B release"
      }
    },
    "qwen/qwen3-32b": {
      "id": "qwen/qwen3-32b",
      "name": "Qwen: Qwen3 32B",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 40960,
      "max_output_tokens": 40960,
      "cost": {
        "input": 5e-08,
        "output": 2e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen332b",
        "constant": "QWEN3_32B",
        "vendor": "qwen",
        "display": "Qwen3 32B",
        "description": "Dense 32B Qwen3 deployment",
        "efficient": false,
        "top_tier": false,
        "generation": "Qwen3-32B",
        "doc_comment": "Qwen3 32B - Dense 32B Qwen3 deployment"
      }
    },
    "qwen/qwen3-8b": {
      "id": "qwen/qwen3-8b",
      "name": "Qwen: Qwen3 8B",
      "reasoning": true,
      "tool_call": false,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 20000,
      "cost": {
        "input": 3.5e-08,
        "output": 1.38e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen38b",
        "constant": "QWEN3_8B",
        "vendor": "qwen",
        "display": "Qwen3 8B",
        "description": "Compact Qwen3 8B deployment",
        "efficient": true,
        "top_tier": false,
        "generation": "Qwen3-8B",
        "doc_comment": "Qwen3 8B - Compact Qwen3 8B deployment"
      }
    },
    "qwen/qwen3-coder": {
      "id": "qwen/qwen3-coder",
      "name": "Qwen: Qwen3 Coder 480B A35B",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 2.2e-07,
        "output": 9.5e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3Coder",
        "constant": "QWEN3_CODER",
        "vendor": "qwen",
        "display": "Qwen3 Coder",
        "description": "Qwen3-based coding model tuned for IDE workflows",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-Coder",
        "doc_comment": "Qwen3 Coder - Qwen3-based coding model tuned for IDE workflows"
      }
    },
    "qwen/qwen3-coder-30b-a3b-instruct": {
      "id": "qwen/qwen3-coder-30b-a3b-instruct",
      "name": "Qwen: Qwen3 Coder 30B A3B Instruct",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 6e-08,
        "output": 2.5e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3Coder30bA3bInstruct",
        "constant": "QWEN3_CODER_30B_A3B_INSTRUCT",
        "vendor": "qwen",
        "display": "Qwen3 Coder 30B A3B Instruct",
        "description": "Large Mixture-of-Experts coding deployment",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-Coder",
        "doc_comment": "Qwen3 Coder 30B A3B Instruct - Large Mixture-of-Experts coding deployment"
      }
    },
    "qwen/qwen3-coder-next": {
      "id": "qwen/qwen3-coder-next",
      "name": "Qwen: Qwen3 Coder Next",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 2.2e-07,
        "output": 9.5e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3CoderNext",
        "constant": "QWEN3_CODER_NEXT",
        "vendor": "qwen",
        "display": "Qwen3 Coder Next",
        "description": "Next-generation Qwen3 coding model with enhanced reasoning",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-Coder",
        "doc_comment": "Qwen3 Coder Next - Next-generation Qwen3 coding model with enhanced reasoning"
      }
    },
    "qwen/qwen3-coder-flash": {
      "id": "qwen/qwen3-coder-flash",
      "name": "Qwen: Qwen3 Coder Flash",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 65536,
      "cost": {
        "input": 3e-07,
        "output": 1.5e-06
      },
      "vtcode": {
        "variant": "OpenRouterQwen3CoderFlash",
        "constant": "QWEN3_CODER_FLASH",
        "vendor": "qwen",
        "display": "Qwen3 Coder Flash",
        "description": "Latency optimised Qwen3 coding model",
        "efficient": true,
        "top_tier": false,
        "generation": "Qwen3-Coder",
        "doc_comment": "Qwen3 Coder Flash - Latency optimised Qwen3 coding model"
      }
    },
    "qwen/qwen3-coder-plus": {
      "id": "qwen/qwen3-coder-plus",
      "name": "Qwen: Qwen3 Coder Plus",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 128000,
      "max_output_tokens": 65536,
      "cost": {
        "input": 1e-06,
        "output": 5e-06
      },
      "vtcode": {
        "variant": "OpenRouterQwen3CoderPlus",
        "constant": "QWEN3_CODER_PLUS",
        "vendor": "qwen",
        "display": "Qwen3 Coder Plus",
        "description": "Premium Qwen3 coding model with long context",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-Coder",
        "doc_comment": "Qwen3 Coder Plus - Premium Qwen3 coding model with long context"
      }
    },
    "qwen/qwen3-max": {
      "id": "qwen/qwen3-max",
      "name": "Qwen: Qwen3 Max",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 256000,
      "max_output_tokens": 32768,
      "cost": {
        "input": 1.2e-06,
        "output": 6e-06
      },
      "vtcode": {
        "variant": "OpenRouterQwen3Max",
        "constant": "QWEN3_MAX",
        "vendor": "qwen",
        "display": "Qwen3 Max",
        "description": "Flagship Qwen3 mixture for general reasoning",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3",
        "doc_comment": "Qwen3 Max - Flagship Qwen3 mixture for general reasoning"
      }
    },
    "qwen/qwen3-next-80b-a3b-instruct": {
      "id": "qwen/qwen3-next-80b-a3b-instruct",
      "name": "Qwen: Qwen3 Next 80B A3B Instruct",
      "reasoning": false,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": 262144,
      "cost": {
        "input": 1e-07,
        "output": 8e-07
      },
      "vtcode": {
        "variant": "OpenRouterQwen3Next80bA3bInstruct",
        "constant": "QWEN3_NEXT_80B_A3B_INSTRUCT",
        "vendor": "qwen",
        "display": "Qwen3 Next 80B A3B Instruct",
        "description": "Next-generation Qwen3 instruction model",
        "efficient": false,
        "top_tier": false,
        "generation": "Qwen3-Next",
        "doc_comment": "Qwen3 Next 80B A3B Instruct - Next-generation Qwen3 instruction model"
      }
    },
    "qwen/qwen3-next-80b-a3b-thinking": {
      "id": "qwen/qwen3-next-80b-a3b-thinking",
      "name": "Qwen: Qwen3 Next 80B A3B Thinking",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 262144,
      "max_output_tokens": null,
      "cost": {
        "input": 1.4e-07,
        "output": 1.2e-06
      },
      "vtcode": {
        "variant": "OpenRouterQwen3Next80bA3bThinking",
        "constant": "QWEN3_NEXT_80B_A3B_THINKING",
        "vendor": "qwen",
        "display": "Qwen3 Next 80B A3B Thinking",
        "description": "Next-generation Qwen3 reasoning release",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3-Next",
        "doc_comment": "Qwen3 Next 80B A3B Thinking - Next-generation Qwen3 reasoning release"
      }
    },
    "qwen/qwen3.5-plus-02-15": {
      "id": "qwen/qwen3.5-plus-02-15",
      "name": "Qwen: Qwen3.5-397B-A17B",
      "description": "The Qwen3.5 native vision-language series Plus models are built on a hybrid architecture that integrates linear attention mechanisms with sparse mixture-of-experts models, achieving higher inference efficiency. In a variety of task evaluations, the 3.5 series consistently demonstrates performance on par with state-of-the-art leading models. Compared to the 3 series, these models show a leap forward in both pure-text and multimodal capabilities.",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text",
          "image"
        ],
        "output": [
          "text"
        ]
      },
      "context": 1000000,
      "max_output_tokens": 256000,
      "cost": {
        "input": 5e-07,
        "output": 2.5e-06
      },
      "vtcode": {
        "variant": "OpenRouterQwen35Plus0215",
        "constant": "QWEN3_5_PLUS_02_15",
        "vendor": "qwen",
        "display": "Qwen3.5-397B-A17B",
        "description": "Qwen3.5 Plus with hybrid linear attention and sparse MoE architecture, 1M context",
        "efficient": false,
        "top_tier": true,
        "generation": "Qwen3.5-Plus",
        "doc_comment": "Qwen3.5-397B-A17B - Native vision-language model with linear attention and sparse MoE, 1M context window"
      }
    },
    "z-ai/glm-5": {
      "id": "z-ai/glm-5",
      "name": "Z.AI: GLM-5",
      "description": "Z.ai's flagship open-source foundation model engineered for complex systems design and long-horizon agent workflows.",
      "reasoning": true,
      "tool_call": true,
      "modalities": {
        "input": [
          "text"
        ],
        "output": [
          "text"
        ]
      },
      "context": 202752,
      "vtcode": {
        "variant": "OpenRouterZaiGlm5",
        "constant": "Z_AI_GLM_5",
        "vendor": "zai",
        "display": "GLM-5",
        "description": "Z.ai flagship GLM-5 model via OpenRouter",
        "efficient": false,
        "top_tier": true,
        "generation": "GLM-5",
        "doc_comment": "GLM-5 - Z.AI GLM-5 flagship foundation model via OpenRouter"
      }
    }
  },
  "default_model": "qwen/qwen3-coder"
}