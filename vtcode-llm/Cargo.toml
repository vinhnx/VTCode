[package]
name = "vtcode-llm"
version = "0.39.13"
edition = "2024"
authors = ["vinhnx <vinhnx@users.noreply.github.com>"]
description = "Prototype extraction of VTCode's unified LLM client layer"
license = "MIT"
publish = false
categories = ["api-bindings", "science::ml"]
keywords = ["vtcode", "llm", "ai", "openai", "anthropic"]

[features]
default = [
    "anthropic",
    "deepseek",
    "google",
    "moonshot",
    "ollama",
    "openai",
    "openrouter",
    "xai",
    "zai",
    "functions",
]

anthropic = []
deepseek = []
google = []
moonshot = []
ollama = []
openai = []
openrouter = []
xai = []
zai = []
functions = []
telemetry = []
mock = ["dep:async-trait"]

[dependencies]
anyhow = "1.0"
async-trait = { version = "0.1", optional = true }
vtcode-commons = { path = "../vtcode-commons", version = "0.39.13" }
vtcode-core = { path = "../vtcode-core" }

[dev-dependencies]
futures = "0.3"
tempfile = "3"
assert_fs = "1.1"
