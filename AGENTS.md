<!-- Generated by Ruler -->

<!-- Source: .ruler/AGENTS.md -->

# VT Code - Agent Guide

## Quick Start

-   **Start session**: `./run.sh` (release) or `./run-debug.sh` (debug)
-   **Single query**: `cargo run -- ask "your query"` (headless testing)

## Build/Test Commands

-   **Build**: `cargo check` (preferred) or `cargo build --release`
-   **Lint**: `cargo clippy` (must pass before commit)
-   **Format**: `cargo fmt`
-   **Test all**: `cargo test` or `cargo nextest run` (preferred)
-   **Test single**: `cargo test test_name` or `cargo nextest run test_name`

## Architecture

-   **vtcode-core/**: Library code (LLM providers, tools, config, MCP integration)
-   **src/**: CLI binary (Ratatui TUI, PTY execution, slash commands)
-   **Config**: `vtcode.toml` (never hardcode), constants in `vtcode-core/src/config/constants.rs`, model IDs in `docs/models.json`
-   **Key modules**: `llm/` (provider abstraction), `tools/` (trait-based), `config/` (TOML parsing)
-   **Integration**: Tree-sitter parsers (Rust/Python/JS/TS/Go/Java), MCP tools, PTY command execution

## Code Style

-   **Error handling**: `anyhow::Result<T>` with `.with_context()` for all fallible functions
-   **Naming**: snake_case (functions/vars), PascalCase (types)
-   **Formatting**: 4 spaces, early returns over nested ifs, descriptive variable names
-   **No emojis, no hardcoded values** (read from vtcode.toml/constants.rs)
-   **Docs**: All .md files in `./docs/` only (not root)

## Tool Selection Decision Tree (Claude Code Pattern)

**Discovery → Context → Execute → Verify → Reply**

```
┌─ Need information?
│  ├─ Structure? → list_files
│  └─ Text patterns? → grep_file
├─ Modifying files?
│  ├─ Surgical edit? → edit_file (preferred)
│  ├─ Full rewrite? → write_file
│  └─ Complex diff? → apply_patch
├─ Running commands?
│  ├─ Interactive shell? → create_pty_session → send_pty_input → read_pty_session
│  └─ One-off command? → run_terminal_cmd
├─ Processing 100+ items?
│  └─ execute_code (Python/JavaScript) for filtering/aggregation
└─ Done?
   └─ ONE decisive reply; stop
```

## Tool Usage Guidelines

-   **Tier 1 - Essential**: list_files, read_file, write_file, grep_file, edit_file, run_terminal_cmd
-   **Tier 2 - Control**: update_plan (TODO list), PTY sessions (create/send/read/close)
-   **Tier 3 - Advanced**: apply_patch, search_tools
-   **Tier 4 - Data Processing**: execute_code, save_skill, load_skill
-   **Command Execution Strategy**:
    -   Interactive work → PTY sessions (create_pty_session → send_pty_input → read_pty_session → close_pty_session)
    -   One-off commands → run_terminal_cmd
    -   AVOID: raw grep/find bash (use grep_file instead)
-   **File Editing Strategy**:
    -   Exact replacements → edit_file (preferred for speed + precision)
    -   Whole-file writes → write_file (when many changes)
    -   Structured diffs → apply_patch (for complex changes)
-   **Search Strategy**:
    -   Text patterns → **grep_file** (uses ripgrep (`rg`, check by `which rg`) by default; falls back to standard grep if ripgrep `rg` unavailable)
    -   Examples: find functions, variables, TODOs, error patterns, API calls, imports
    -   Use regex patterns: `fn \w+\(`, `TODO|FIXME`, `\.unwrap()`, `import .*from`
    -   Use literal mode for exact strings: `literal: true`
    -   Tool discovery → search_tools before execute_code
-   **File Listing Strategy**:
    -   list_files with `mode='list'`: Single-directory listing
    -   list_files with `mode='recursive'` + `name_pattern`: Glob-style file search
    -   list_files with `mode='find_name'`: Find by exact name
    -   list_files with `mode='find_content'`: Find files containing pattern
    -   **IMPORTANT**: Tool returns sampled output (first N items) to prevent buffer overflow, but internally captures all matches. Use pagination (`page`, `per_page`) to access full results

## File Listing Output Behavior (Smart Sampling)

When using `list_files` or file discovery tools:

1. **Full Internal Processing**: Tool processes ALL matching files internally
2. **Output Sampling**: Response shows only first page (default 50 items) or configured `per_page` limit
3. **No Data Loss**: Complete file count provided in `total` field and pagination metadata
4. **Pagination Support**: Use `page` parameter to access additional results:
    ```
    → list_files(path="src", mode="recursive", name_pattern="*.rs", page=2, per_page=50)
    ```
5. **Token Efficiency**: Agent replies with concise samples; response is truncated gracefully in output

**Example Flow:**

```
Agent calls: list_files(path="src", mode="recursive", name_pattern="*", max_items=1000)
↓
Tool finds 342 TypeScript files internally
↓
Response returns: { "items": [first 50], "total": 342, "has_more": true }
↓
Agent uses complete internal list for filtering/searching
↓
If needed, agent calls again with page=2 to fetch next batch
```

## Code Execution & Skills (High-Impact Features)

### When to Use Code Execution

Use `execute_code()` to:

-   **Filter large datasets** (100+ items) locally in Python/JavaScript sandbox
-   **Transform data** before returning (map, reduce, group operations)
-   **Implement complex logic** (loops, conditionals, error handling)
-   **Chain tools together** in single execution (90% token reduction)
-   **Save patterns as skills** for 80%+ reuse on repeated tasks

### Code Execution Workflow

1. **Discover Tools**: `search_tools(keyword="xyz", detail_level="name-only")` - minimal context
2. **Write Code**: Python 3 or JavaScript calling tools as library functions
3. **Execute**: `execute_code(code=..., language="python3")` - runs in sandbox
4. **Save Pattern**: `save_skill(name="...", code=..., language="...")` for future reuse
5. **Reuse**: `load_skill(name="...")` - instant execution, no re-run

### Safety & Security

-   Sandbox isolation: Cannot escape to filesystem beyond WORKSPACE_DIR
-   PII protection: Sensitive data auto-tokenized before return
-   Timeout enforcement: 30-second max execution
-   Resource limits: Memory and CPU bounded

### Example: Filter 1000 Test Files

**With code execution** (recommended):

```python
files = list_files(path="/workspace", recursive=True)
test_files = [f for f in files if "test" in f and f.endswith(".rs")]
result = {"count": len(test_files), "files": test_files[:20]}
```

### IMPORTANT

-   **DO NOT** print API keys or debug/logging output. THIS IS IMPORTANT!
-   **DO NOT** git commit automatically without user review.
-   Always use code execution for 100+ item filtering (massive token savings)
-   Save skills for repeated patterns (80%+ reuse ratio documented)
-   Regularly run `cargo clippy` and `cargo fmt` to maintain code quality
-   Documents: every documents must be grouped in ./docs/, no documents in root folder. Ideally create grouped documents folder inside ./docs/ if there are many documents about one topic.

## Execution Algorithm (with Decision Points)

### Phase 1: Understanding

1. Parse the request once
2. Confirm understanding if intent is unclear
3. DO NOT create TODO lists unless work clearly spans 3+ steps
4. Immediately search for context

<good-example>
User: "Add error handling to fetch_user"
→ Search for fetch_user implementation
→ Identify current error paths
→ Add try-catch + logging in 1-2 calls
→ Reply: "Done. Added error handling for network + parse errors."
</good-example>

<bad-example>
User: "Add error handling to fetch_user"
→ "Let me create a TODO list first"
→ "Step 1: Find the function. Step 2: Add error handling. Step 3: Test."
→ [starts implementation]
→ [keeps asking to re-assess]
</bad-example>

### Phase 2: Context Gathering

**Algorithm:**

```
if task is simple (1-2 files affected)
  → list_files for structure
  → grep_file to find relevant code
  → read_file (targeted)
else
  → grep_file to locate patterns across codebase
  → search_tools to discover available tools
  → read_file only what's needed
```

**IMPORTANT:** Search BEFORE reading whole files. Never read 5+ files without searching first.

**grep_file Best Practices:**

-   Start narrow: Search specific directory/file type with `glob` or `path` parameter
-   Use `max_results` to limit output (default 100)
-   Combine `literal: true` for exact matches or regex for patterns
-   Example: Find all function definitions: `grep_file(pattern="^fn ", path="src", glob="*.rs")`
-   Example: Find TODO comments: `grep_file(pattern="TODO|FIXME", case_sensitive=false)`

### Phase 3: Execution

-   Consolidate commands: Do 3-4 edits in single turn instead of 3-4 turns
-   Use code execution for 100+ item processing (don't return raw lists to model)
-   Verify impactful changes (tests, diffs)
-   Stop immediately after solution is complete (don't re-call model)

### Phase 4: Reply

-   Single decisive message
-   No hypothetical plans after work is done
-   Summarize what was ACTUALLY changed, not what could be changed
-   Avoid preamble ("Let me explain...") unless user asks

## File Listing Agent Behavior (Implementation Pattern)

### Smart Sampling in Agent Responses

**Pattern for all agents using list_files tools:**

1. **Call the tool** with full parameters (max_items, pagination, filters)
2. **Receive sampled response** (first N items + metadata)
3. **Show small sample in output** (5-10 items) to prevent buffer overflow
4. **Maintain full context internally** - the tool has already processed complete file list
5. **Reference total count** in your reply: `"Found 342 files. Sample: [list 5], ..."`
6. **Use pagination for depth** if needed: `page=2, per_page=50`

**Example Agent Pattern:**

```
User: "Find all Rust test files"
→ Call: list_files(path=".", mode="recursive", name_pattern="*.rs", max_items=1000)
→ Tool returns: 156 files (shows first 50 in items array)
→ Agent replies: "Found 156 Rust files. Sample: main.rs, lib.rs, ... (10 items shown)"
→ If needed for subsequent operations, agent uses complete file list internally
```

## grep_file Usage Patterns

### When to Use grep_file

Use `grep_file` for:

-   Finding function/variable definitions across codebase
-   Locating error messages, TODOs, FIXMEs
-   Searching for API calls or imports
-   Identifying patterns in code (e.g., all `unwrap()` calls)
-   Verifying where a change needs to be applied

### grep_file Examples

**Find all function definitions in Rust:**

```
grep_file(pattern="^pub fn\\s+\\w+", path="src", glob="**/*.rs")
```

**Find all TODOs and FIXMEs:**

```
grep_file(pattern="TODO|FIXME", case_sensitive=false, path="src")
```

**Find exact string matches (literal search):**

```
grep_file(pattern="const ERROR_MSG", literal=true, path="src")
```

**Search specific file type in directory:**

```
grep_file(pattern="import.*from", path="web/src", glob="**/*.tsx")
```

**Find imports from a package:**

```
grep_file(pattern="import.*from ['\"]@core", path="src", glob="**/*.ts")
```

### grep_file Strategy

1. **Be specific with path and glob**: Narrow search scope to avoid noise
2. **Use glob patterns**: `**/*.rs` for all Rust, `src/**/*.ts` for TypeScript in src/
3. **Combine with context**: Use `context_lines=3` to see surrounding code
4. **Limit results**: Default 100 is usually good; increase only if needed
5. **Use literal mode for exact matches**: Faster and clearer intent

## Tone and Steerability (Claude Code Pattern)

### Tone Guidelines

-   **IMPORTANT:** Do NOT answer with unnecessary preamble or postamble (such as explaining your code or summarizing your action), unless the user asks you to.
-   Keep answers concise, direct, and free of filler
-   Prefer direct answers over meta commentary
-   Only use emojis if the user explicitly requests it
-   When you cannot help, do NOT explain why or what it could lead to (comes across as preachy)

### Steering the Model

Unfortunately, "IMPORTANT" is still state-of-the-art for steering model behavior:

```
# Examples of effective steering:
- IMPORTANT: You must NEVER generate or guess URLs unless confident
- VERY IMPORTANT: You MUST avoid using bash find/grep; use Grep, Glob, or Task instead
- IMPORTANT: DO NOT ADD ANY COMMENTS unless asked
- IMPORTANT: When listing files, show only 5-10 samples in output but work with complete list internally
```

### Examples of Good vs Bad Behavior

<good-example>
User: "Find and update all database queries"
→ Use grep_file to locate SQL patterns
→ Use execute_code to aggregate results into summary
→ Edit affected files in batches (5 files per turn)
→ Test via PTY session
→ Reply: "Updated 12 queries. Changed pagination limits from 100 to 50. Tests passing."
</good-example>

<bad-example>
User: "Find and update all database queries"
→ "Let me analyze the codebase to understand the query patterns..."
→ grep -r "SELECT" (raw bash search returns 500+ results)
→ "Here's what I found. Should I proceed with updates?"
→ Waits for user confirmation before continuing
→ Makes changes one file at a time
</bad-example>

### When to Use update_plan (TODO List)

**Use update_plan ONLY if:**

-   Work clearly spans 4+ logical steps
-   Steps have dependencies
-   User explicitly asked for a plan
-   Complex refactoring with 5+ files

**Skip update_plan if:**

-   Task is simple (1-3 files, 1-2 steps)
-   Work can be completed in single turn
-   User just asked for a quick change

<good-example>
"Refactor payment module to use async/await"
→ Task spans multiple logical steps: identify functions, refactor signatures, update callers, test
→ Use update_plan with 5-6 steps
→ Reference plan in each subsequent message
</good-example>

<bad-example>
"Add a new field to UserModel"
→ create update_plan("Add username field to UserModel" → 5 steps)
✗ Overkill for simple field addition
→ Just do it in 1 turn
</bad-example>
